{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune NER Model\n",
    "To fine-tune a Named Entity Recognition (NER) model to extract key entities (products, prices, and location) from Amharic Telegram messages, we will follow these steps.\n",
    "\n",
    "**Step 1: Set Up Environment with GPU Support**\n",
    "\n",
    "Use Google Colab or GPU-Enabled Environment Ensure that selected a runtime with GPU in Google Colab:\n",
    "\n",
    "Go to Runtime > Change runtime type > Select GPU.\n",
    "Install Necessary Libraries\n",
    "\n",
    "Run the following commands in a code cell to install the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XLMRobertaTokenizerFast\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, Features, Sequence, Value\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import XLMRobertaTokenizerFast\n",
    "from datasets import Dataset, Features, Sequence, Value\n",
    "from transformers import TrainingArguments\n",
    "from transformers import XLMRobertaForTokenClassification, AutoModelForTokenClassification, AutoTokenizer, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the required libraries are installed, we will use transformers for the model and datasets for loading data, and seqeval for evaluating the NER model.\n",
    "\n",
    "**Step 2: Load the Labeled Dataset from CoNLL File**\n",
    "\n",
    "Load the CoNLL Dataset\n",
    "we can load our CoNLL formatted data into a DataFrame. Here's how we can do that:\n",
    "Upload the conll file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load CoNLL formatted data\n",
    "def load_conll(file_path):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sentence = []\n",
    "        label = []\n",
    "        for line in f:\n",
    "            if line.strip():  # Non-empty line\n",
    "                token, label_item = line.split()\n",
    "                sentence.append(token)\n",
    "                label.append(label_item)\n",
    "            else:  # Empty line indicates end of a sentence\n",
    "                sentences.append(sentence)\n",
    "                labels.append(label)\n",
    "                sentence = []\n",
    "                label = []\n",
    "    return pd.DataFrame({'tokens': sentences, 'labels': labels})\n",
    "\n",
    "# Load your CoNLL file\n",
    "df = load_conll('labeled_data_conll.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
